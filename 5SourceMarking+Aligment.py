import os
import pandas as pd
import json
import matplotlib.pyplot as plt

# æ–‡ä»¶è·¯å¾„ï¼ˆè¯·ç¡®ä¿è·¯å¾„ã€æ–‡ä»¶åå‡æ­£ç¡®ï¼‰
original_csv_path = r""
result_csv_path = r""

# æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
if not os.path.exists(original_csv_path):
    print(f"é”™è¯¯ï¼šåŸå§‹æ–‡ä»¶æœªæ‰¾åˆ°ï¼š{original_csv_path}")
    exit(1)
if not os.path.exists(result_csv_path):
    print(f"é”™è¯¯ï¼šç»“æœæ–‡ä»¶æœªæ‰¾åˆ°ï¼š{result_csv_path}")
    exit(1)

# å°è¯•è¯»å– CSV æ–‡ä»¶ï¼Œé‡åˆ°ç¼–ç é”™è¯¯æ—¶æ”¹ç”¨ gbk ç¼–ç 
try:
    original_df = pd.read_csv(original_csv_path, encoding="utf-8")
except UnicodeDecodeError:
    original_df = pd.read_csv(original_csv_path, encoding="gbk")

try:
    result_df = pd.read_csv(result_csv_path, encoding="utf-8")
except UnicodeDecodeError:
    result_df = pd.read_csv(result_csv_path, encoding="gbk")

# === STEP1: åå†™å¯¹é½ç»“æœåˆ°åŸå§‹å›¾è°±æ–‡ä»¶ ===
aligned = result_df[result_df["aligned"] == True]
alias_map = dict(zip(aligned["input"], aligned["matched_kg_entity"]))

original_df["subject_aligned"] = original_df["subject"].apply(lambda x: alias_map.get(x, x))
original_df["object_aligned"] = original_df["object"].apply(lambda x: alias_map.get(x, x))
original_df.to_csv("updated_triples_with_alignment.csv", index=False)
print("åŸå›¾è°±å·²æ·»åŠ æ ‡å‡†åŒ–å®ä½“åˆ—å¹¶ä¿å­˜ä¸º updated_triples_with_alignment.csv")

# === STEP2: ä¿å­˜ alias å­—å…¸ ===
alias_dict = dict(zip(aligned["input"], aligned["matched_kg_entity"]))
with open("aligned_alias_dictionary.json", "w", encoding="utf-8") as f:
    json.dump(alias_dict, f, ensure_ascii=False, indent=2)
print("å·²ä¿å­˜ alias æ˜ å°„å­—å…¸åˆ° aligned_alias_dictionary.json")

# === STEP3: åˆ†ææœªå¯¹é½å®ä½“ ===
unmatched = result_df[result_df["aligned"] == False]
print("\nTop æœªåŒ¹é…å®ä½“ï¼š")
print(unmatched["input"].value_counts().head(20))

# === STEP4: èåˆå›¾è°±å»é‡ ===
deduplicated_df = original_df.drop_duplicates(subset=["subject_aligned", "relation", "object_aligned"])
# å¯ç»§ç»­æ·»åŠ æ¥æºå›¾è°±å­—æ®µå¤„ç†

# === STEP5: æ„å»ºèåˆæŠ¥å‘Š CSV ===
fusion_report = result_df[["input", "matched_kg_entity", "match_type", "similarity_score", "matched_triple", "match_source", "aligned"]]
fusion_report.to_csv("entity_fusion_report.csv", index=False)
print("å·²ç”ŸæˆèåˆæŠ¥å‘Šæ–‡ä»¶ entity_fusion_report.csv")

# === STEP6: ç”Ÿæˆå¯¹é½æ‘˜è¦æŠ¥å‘Š ===
total = len(result_df)
aligned_count = result_df["aligned"].sum()
unaligned_count = total - aligned_count
match_counts = result_df["match_type"].value_counts()

# é¥¼å›¾ï¼šåŒ¹é…æ–¹å¼å æ¯”
plt.figure(figsize=(6, 6))
match_counts.plot.pie(autopct='%1.1f%%', startangle=140)
plt.title("Match Type Distribution")
plt.ylabel("")
plt.tight_layout()
plt.savefig("match_type_distribution.png")
plt.close()

# ç›¸ä¼¼åº¦åˆ†å¸ƒå›¾ï¼ˆä»…é™å·²åŒ¹é…ï¼‰
plt.figure(figsize=(6, 4))
result_df[result_df["aligned"]]["similarity_score"].hist(bins=20)
plt.title("Similarity Score Distribution")
plt.xlabel("Score")
plt.ylabel("Frequency")
plt.tight_layout()
plt.savefig("similarity_score_histogram.png")
plt.close()

# Top æœªåŒ¹é…å®ä½“
top_unmatched = result_df[result_df["aligned"] == False]["input"].value_counts().head(10)

# è¾“å‡º Markdown æŠ¥å‘Š
with open("fusion_summary_report.md", "w", encoding="utf-8") as f:
    f.write("# Entity Alignment Fusion Report\n\n")
    f.write(f"**Total entities processed:** {total}\n\n")
    f.write(f"- âœ… Aligned: `{aligned_count}`\n")
    f.write(f"- âŒ Not aligned: `{unaligned_count}`\n\n")
    f.write("## Match Type Distribution\n\n")
    f.write("![Match Type Distribution](match_type_distribution.png)\n\n")
    f.write("## Similarity Score Histogram (Aligned only)\n\n")
    f.write("![Similarity Score Histogram](similarity_score_histogram.png)\n\n")
    f.write("## Top 10 Unmatched Entities\n\n")
    f.write("```\n")
    f.write(top_unmatched.to_string())
    f.write("\n```\n")

print("ğŸ“„ å·²ç”Ÿæˆèåˆæ‘˜è¦æŠ¥å‘Šï¼šfusion_summary_report.md å’Œä¸¤å¼ å›¾è¡¨")
